{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EX6: \n",
    "\n",
    "Describe the class of strings matched by the following regular expressions:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(1) [a-zA-Z]+ \n",
    "(2) [A-Z][a-z]*\n",
    "(3) p[aeiou]{,2}t \n",
    "(4) \\d+(\\.\\d+)?\n",
    "(5) ([^aeiou][aeiou][^aeiou])*\n",
    "(6) \\w+|[^\\w\\s]+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your answers using nltk.re_show().\n",
    "\n",
    "Answers:\n",
    "\n",
    "* (1): Alphanumeric words\n",
    "* (2): Alphanumeric words, capitalized start letter\n",
    "* (3): Words starting with p, ending with t, with at most 2 vowels in between\n",
    "* (4): Decimal numbers, captures the decimal.\n",
    "* (5): strings that repeat the pattern non-lowercase-vowel non-lowercase-concosant non-lowercase-vowel fully, i.e. must end with a consonant, and the length is divisble by 3. Non-vowel/cons can be numbers, spaces, or symbols\n",
    "* (6): A word cosisting of either alphanumeric characters or digits/non-whitespace symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "crime_and_punishment = urlopen(url).read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern (1): ['The', 'Project', 'Gutenberg', 'EBook', 'of']\n",
      "Pattern (2): ['The', 'Project', 'Gutenberg', 'E', 'Book']\n",
      "Pattern (3): ['poet', 'put', 'pt', 'pt', 'pt']\n",
      "Pattern (4): ['.91231', '']\n",
      "Pattern (5): ['', '', 'he ', '', 'roj']\n",
      "Pattern (6): ['\\ufeff', 'The', 'Project', 'Gutenberg', 'EBook']\n"
     ]
    }
   ],
   "source": [
    "p1 = r'[a-zA-Z]+'\n",
    "p2 = r'[A-Z][a-z]*'\n",
    "p3 = r'p[aeiou]{,2}t'\n",
    "p4 = r'\\d+(\\.\\d+)?'\n",
    "p5 = r'([^aeiou][aeiou][^aeiou])*'\n",
    "p6 = r'\\w+|[^\\w\\s]+'\n",
    "\n",
    "print(\"Pattern (1):\", re.findall(p1, crime_and_punishment)[:5])\n",
    "print(\"Pattern (2):\", re.findall(p2, crime_and_punishment)[:5])\n",
    "print(\"Pattern (3):\", re.findall(p3, crime_and_punishment)[:5])\n",
    "print(\"Pattern (4):\", re.findall(p4, \"12.91231, not a decimal number / 10\")[:5])\n",
    "print(\"Pattern (5):\", re.findall(p5, crime_and_punishment)[:5])\n",
    "print(\"Pattern (6):\", re.findall(p6, crime_and_punishment)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EX30\n",
    "\n",
    "Use the Porter Stemmer to normalize some tokenized text, calling the stemmer on each word. Do the same thing with the Lancaster Stemmer and see if you observe any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(crime_and_punishment)\n",
    "tokens = list(filter(lambda t: t.isalpha(), tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_porter = [porter.stem(t) for t in tokens];\n",
    "tokens_lancaster = [lancaster.stem(t) for t in tokens];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6183"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens_porter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5146"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens_lancaster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancaster is a more aggressive stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
