{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity\n",
    "### H3: Random Hypothesis\n",
    "* Randomly wired networks lack an inherent community structure.\n",
    "* By comparing the link density of a community with the link density obtained for the same group of nodes for a randomly rewired network, we could decide if the original community corresponds to a dense subgraph, or its connectivity pattern emerged by chance.\n",
    "\n",
    "\n",
    "### Modularity\n",
    "*The \"quality\" of systematic deviations from a random configuration of a graph.*\n",
    "* Allows us to rate communities and compare them\n",
    "\n",
    "Consider a graph, G:\n",
    "* $N$ nodes, $L$ links\n",
    "* $n_c$ communities, each having $N_c$ nodes and $L_c$ links ($c = 1..n_c$)\n",
    "* If $L_c > L_{expect}(C_c)$ then C_c is likely a community\n",
    "* Measure difference between actual wiring diagram ($A_{ij}$) and the expected number of links between $i$ and $j$ in a random graph with wiring probability $p_{ij}$.\n",
    "\n",
    "$M_c = \\frac{1}{2L} \\sum_{i,j \\in C_c}{(A_{ij} - p_{ij})} = \n",
    "\\frac{L_C}{L} - \\left(\\frac{k_c}{2L}\\right)^2 $, \n",
    "where $p_{ij} = \\frac{k_i k_j}{2L}$\n",
    "\n",
    "* If $M_c > 0$ then the subgraph $C_c$ has more links than expected and represents a potential community.\n",
    "* If $M_c = 0$ then the connectivity is what can be expected from a random graph, and nothing final can be concluded.\n",
    "* If $M_c = 0$ then $C_c$ is not a community.\n",
    "\n",
    "Modularity of a partition which breaks a graph into $n_c$ communities:\n",
    "$M = \\sum_{c=1}^{c_n}M_c$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explain the concept of modularity in your own words.\n",
    "    * A measure that allows us to compare the quality of communities in a quantitative manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPUBLICAN = \"Republican\"\n",
    "DEMOCRATIC = \"Democratic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io, re, warnings, community\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install \"community\"\n",
    "!pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_h115 = 'https://raw.githubusercontent.com/suneman/socialgraphs2018/master/files/data_US_congress/H115.csv'\n",
    "df = pd.read_csv(url_h115)\n",
    "page_names = list(df.WikiPageName)\n",
    "dict_politician = dict(zip(df.WikiPageName, zip(df.Party, df.State)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pathlib\n",
    "import requests\n",
    "\n",
    "def save_to_file(name, content):\n",
    "    pathlib.Path('h115').mkdir(parents=True, exist_ok=True)\n",
    "    filename = 'h115/%s.txt' % name\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(content)\n",
    "    f.close() \n",
    "         \n",
    "def fetch_pages(page_list):\n",
    "    for page_name in page_list:\n",
    "        url = \"http://en.wikipedia.org/w/api.php/?action=query&titles=%s&prop=revisions&rvprop=timestamp|content&format=json&rvdir=older&rvstart=2019-01-03T00:00:00Z&rvend=2000-01-03T00:00:00Z&rvlimit=1\" % page_name\n",
    "        wiki_content = requests.get(url).text\n",
    "        save_to_file(page_name, wiki_content)\n",
    "        \n",
    "fetch_pages(page_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A politcian class for storing data in a neat way.\n",
    "class Politician:\n",
    "    def __init__(self, wiki_name, party, state):\n",
    "        self.WikiName = wiki_name\n",
    "        self.Party = party\n",
    "        self.State = state\n",
    "    \n",
    "    def to_string(self):\n",
    "        return \"TwitterName: %s, Party: %s, Sate: %s\" % (self.WikiName, self.Party, self.State)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.WikiName)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "                self.__class__ == other.__class__ and \n",
    "                self.WikiName == other.WikiName\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a WikiPage txt file, scans it for links to other Wikipages,\n",
    "# and returns a list of the found links\n",
    "def get_article_links(wiki_name, directory=\"h115\"):\n",
    "    # The regex pattern for recognizing links on the form [x |Â y]\n",
    "    # and only capturing 'x'.\n",
    "    article_pattern = r'\\[\\[([^\\]]*?)(?:\\|.*?)*\\]\\]'\n",
    "    path = './%s/%s.txt' % (directory, wiki_name)\n",
    "    article = io.open(path, 'r', encoding='utf-8').read()\n",
    "    article_links = re.findall(article_pattern, article)\n",
    "    article_links = [a.replace(' ', '_') for a in article_links]\n",
    "    return article_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()\n",
    "\n",
    "for a_wiki_name in dict_politician:\n",
    "    # Create politician node (a)\n",
    "    a_party, a_state = dict_politician[a_wiki_name]\n",
    "    a_node = Politician(a_wiki_name, a_party, a_state)\n",
    "    a_article_links = get_article_links(a_wiki_name)\n",
    "    \n",
    "    for b_wiki_name in a_article_links:\n",
    "        if b_wiki_name in page_names:\n",
    "            b_party, b_state = dict_politician[b_wiki_name]\n",
    "            b_node = Politician(b_wiki_name, b_party, b_state)\n",
    "            DG.add_edge(a_node, b_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the undirected version of the graph for the 115th house of representatives.\n",
    "* Compute the modularity when you partition nodes based on their party. Modularity is described in the Network Science book, section 9.4). * * Use equation 9.12 in the book to calculate the modularity M of the parties-partitioning. Are the parties good community?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert graph, extract nodes\n",
    "UG = DG.to_undirected()\n",
    "nodes = UG.nodes()\n",
    "\n",
    "# Split nodes on party\n",
    "repub_nodes = [node for node in nodes if node.Party == REPUBLICAN]\n",
    "demo_nodes = [node for node in nodes if node.Party == DEMOCRATIC]\n",
    "\n",
    "# Create subgraphs\n",
    "repub_subgraph = UG.subgraph(repub_nodes)\n",
    "demo_subgraph = UG.subgraph(demo_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M_c = \\frac{1}{2L} \\sum_{i,j \\in C_c}{(A_{ij} - p_{ij})} = \n",
    "\\frac{L_C}{L} - \\left(\\frac{k_c}{2L}\\right)^2 $, \n",
    "where $p_{ij} = \\frac{k_i k_j}{2L}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. party modularity: 0.5419020430161754\n"
     ]
    }
   ],
   "source": [
    "repub_part = community.best_partition(repub_subgraph)\n",
    "demo_part = community.best_partition(demo_subgraph)\n",
    "\n",
    "mod_repub = community.modularity(repub_part, repub_subgraph)\n",
    "mod_demo = community.modularity(demo_part, demo_subgraph)\n",
    "party_modularity = (mod_repub + mod_demo) / 2\n",
    "\n",
    "print(\"Avg. party modularity:\", party_modularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Since the parties have an average $M_c$ value greater than zero, parties are potential communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska has no links.\n",
      "Oregon has no links.\n",
      "Connecticut has no links.\n",
      "Mississippi has no links.\n",
      "Oregon has no links.\n",
      "Colorado has no links.\n",
      "Connecticut has no links.\n",
      "Idaho has no links.\n",
      "Oregon has no links.\n",
      "Rhode Island has no links.\n",
      "Iowa has no links.\n",
      "Connecticut has no links.\n",
      "Colorado has no links.\n",
      "Iowa has no links.\n",
      "Colorado has no links.\n",
      "Vermont has no links.\n",
      "Colorado has no links.\n",
      "Mississippi has no links.\n",
      "Connecticut has no links.\n",
      "Colorado has no links.\n",
      "Oregon has no links.\n",
      "Rhode Island has no links.\n",
      "Arkansas has no links.\n",
      "Idaho has no links.\n",
      "South Dakota has no links.\n",
      "Mississippi has no links.\n",
      "Colorado has no links.\n",
      "Arkansas has no links.\n",
      "Oregon has no links.\n",
      "Hawaii has no links.\n",
      "North Dakota has no links.\n",
      "Connecticut has no links.\n",
      "Hawaii has no links.\n",
      "Iowa has no links.\n",
      "Colorado has no links.\n",
      "Arkansas has no links.\n",
      "Arkansas has no links.\n",
      "Iowa has no links.\n",
      "Mississippi has no links.\n",
      "Delaware has no links.\n",
      "Wyoming has no links.\n",
      "Mean state modularity: 0.3621327528394268\n"
     ]
    }
   ],
   "source": [
    "states = list(df.State)\n",
    "state_modularity = []\n",
    "\n",
    "for state in states:\n",
    "    state_nodes = [node for node in nodes if node.State == state]\n",
    "    state_subgraph = UG.subgraph(state_nodes)\n",
    "    state_part = community.best_partition(state_subgraph)\n",
    "    try:\n",
    "        mod = community.modularity(state_part, state_subgraph)\n",
    "        state_modularity.append(mod)\n",
    "    except:\n",
    "        print(state, \"has no links.\")\n",
    "\n",
    "m = np.array(state_modularity).mean()\n",
    "print(\"Mean state modularity:\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the exercise above by considering states instead of parties. Are the states good communities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Would you expect these results in light of what we have found in the previous exercises?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Python Louvain-algorithm implementation to find communities in the full house of representatives network. \n",
    "* Report the value of modularity found by the algorithm. \n",
    "* Is it higher or lower than what you found above for the parties/states as communities? \n",
    "* What does this comparison reveal about the parties/states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4552256058673469"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_part = community.best_partition(UG)\n",
    "full_mod = community.modularity(full_part, UG)\n",
    "full_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "* Slightly below the average for the parties, meaning parties is probably a better foundation for communities within the WikiPedia context, than just taking the \"best\" partitions in the full graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
